# @package agent
_target_: agent.atr_rnd.ATR_RNDAgent
name: atr
reward_free: ${reward_free}
obs_type: ??? # to be specified later
obs_shape: ??? # to be specified later
action_shape: ??? # to be specified later
device: ${device}
lr: 1e-4
critic_target_tau: 0.01
update_every_steps: 2
use_tb: ${use_tb}
use_wandb: ${use_wandb}
num_expl_steps: ??? # to be specified later
hidden_dim: 1024
feature_dim: 50
stddev_schedule: 0.2
stddev_clip: 0.3
atr_scale: 1.0
nstep: 3
batch_size: 32 #1024
init_critic: true
update_encoder: ${update_encoder}


#exclude_matching_parameters_from_lars: [".bias", ".bn"]
projection_mlp_layers: 3
prediction_mlp_layers: 0
#final_lr_schedule_value: 0.002
#mlp_normalization: "bn"
#lars_warmup_epochs: 10
skill_dim: 16
num_action_skill: 50
invariance_loss_weight: 25.0
variance_loss_weight: 25.0
covariance_loss_weight: 1.0
variance_loss_epsilon: 1e-04
#lars_eta: 1e-3